{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Technical University of Munich<br>\n",
    "Professorship of Environmental Sensing and Modeling<br><br>*\n",
    "**Author:**  Daniel KÃ¼hbacher<br>\n",
    "**Date:**  30.10.2023\n",
    "\n",
    "--- \n",
    "\n",
    "# BAST Location processing\n",
    "\n",
    "This notebook preprocessed the location information of the BAST traffic counting stations in Bavaria. \n",
    "\n",
    "The raw data was retrieved manually from:\n",
    "https://www.bast.de/DE/Verkehrstechnik/Fachthemen/v2-verkehrszaehlung/Daten/2020_1/Jawe2020.html;jsessionid=B7EAB647A5E95B1101BAD1A925FF188C.live21304?cms_map=1&cms_filter=true&cms_jahr=Jawe2020&cms_land=9&cms_strTyp=&cms_str=&cms_dtvKfz=&cms_dtvSv=\n",
    "\n",
    "**Required steps**\n",
    "- Import file and convert columns to meaningful datatypes\n",
    "- Divide location (represented as single point) into two points for both directions since for\n",
    "  motorways, each direction is represented as indiviudal road link.\n",
    "\n",
    "**Following steps should be done manually in QGIS**\n",
    "- delete useless stations outside the area of interest\n",
    "- assign each detector to the street link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# import custom modules\n",
    "sys.path.append('../../utils/')\n",
    "import data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_paths.BAST_COUNTING_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and clean raw data from *.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw bast location data\n",
    "bast_raw = pd.read_csv(data_path+'bast_locations_bavaria.csv', \n",
    "                       delimiter=';', decimal = ',', encoding='ISO-8859-1')\n",
    "\n",
    "# only use 8+1 counters\n",
    "bast_loc = bast_raw[bast_raw['Erf_Art']== '8+1']\n",
    "\n",
    "# define relevant columns\n",
    "relevant_columns = ['DZ_Nr', 'Hi_Ri1', 'Hi_Ri2',\n",
    "                    'Koor_WGS84_N', 'Koor_WGS84_E']\n",
    "\n",
    "bast_loc = bast_loc[relevant_columns]\n",
    "bast_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide location data into two directions\n",
    "columns = ['MST_ID', 'DETEKTOR_ID', 'FAHRTRICHTUNG', \n",
    "           'LONGITUDE', 'LATITUDE']\n",
    "row_lst = []\n",
    "\n",
    "def coordinate_offset(direction, lon, lat): \n",
    "    offset = 0.0005\n",
    "    match direction:\n",
    "        case 'N':\n",
    "            return {'LONGITUDE': lon, \n",
    "                    'LATITUDE' : lat+offset}\n",
    "        case 'O':\n",
    "            return {'LONGITUDE': lon-offset, \n",
    "                    'LATITUDE' : lat}\n",
    "        case 'S':\n",
    "            return {'LONGITUDE': lon, \n",
    "                    'LATITUDE' : lat-offset}\n",
    "        case 'W':\n",
    "            return {'LONGITUDE': lon+offset,\n",
    "                    'LATITUDE' : lat}\n",
    "\n",
    "for idx,row in bast_loc.iterrows():\n",
    "    row_dict_R1 = { 'MST_ID': row['DZ_Nr'],\n",
    "                    'DETEKTOR_ID': int(str(row['DZ_Nr']) + '1'),\n",
    "                    'FAHRTRICHTUNG': row['Hi_Ri1']}\n",
    "    \n",
    "    row_dict_R2 = { 'MST_ID': row['DZ_Nr'],\n",
    "                    'DETEKTOR_ID': int(str(row['DZ_Nr']) + '2'),\n",
    "                    'FAHRTRICHTUNG': row['Hi_Ri2']}\n",
    "    \n",
    "    row_dict_R1.update(coordinate_offset(direction = row['Hi_Ri1'],\n",
    "                                         lon = row['Koor_WGS84_N'],\n",
    "                                         lat = row['Koor_WGS84_E']))\n",
    "    \n",
    "    row_dict_R2.update(coordinate_offset(direction = row['Hi_Ri2'],\n",
    "                                         lon = row['Koor_WGS84_N'],\n",
    "                                         lat = row['Koor_WGS84_E']))\n",
    "    \n",
    "    row_lst.append(row_dict_R1)\n",
    "    row_lst.append(row_dict_R2)\n",
    "    \n",
    "bast = pd.DataFrame(row_lst, columns = columns)\n",
    "bast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save preprocessed bast locations as *.gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bast = gpd.GeoDataFrame(\n",
    "    bast, geometry=gpd.points_from_xy(bast.LATITUDE, bast.LONGITUDE))\n",
    "bast.drop(['LATITUDE', 'LONGITUDE'], axis = 1, inplace = True)\n",
    "bast = bast.set_crs(epsg='4326')\n",
    "\n",
    "# save data\n",
    "bast.to_file(data_path + \"bast_locations_cleaned.gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
