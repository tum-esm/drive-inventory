{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Technical University of Munich<br>\n",
    "Professorship of Environmental Sensing and Modeling<br><br>*\n",
    "**Author:**  Daniel KÃ¼hbacher<br>\n",
    "**Date:**  15.11.2023\n",
    "\n",
    "--- \n",
    "\n",
    "# Comparison of the counting data and VISUM dtv values\n",
    "\n",
    "<!--Notebook description and usage information-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import stat\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# import custom modules\n",
    "sys.path.append('../../utils')\n",
    "import data_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preapre datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_data_path = data_paths.COUNTING_PATH + 'counting_data_combined.parquet'\n",
    "cnt_data = pd.read_parquet(cnt_data_path)\n",
    "cnt_data_normweekday_2019 = cnt_data[(cnt_data['date'].between('2019-01-01', '2019-12-31')) &  \n",
    "                                     (cnt_data['day_type'] == 0)]\n",
    "\n",
    "visum_links_path = data_paths.VISUM_FOLDER_PATH + 'visum_links.gpkg'\n",
    "visum_links = gpd.read_file(visum_links_path)\n",
    "\n",
    "visum_links['dtv_PC'] = visum_links['dtv_SUM'] * visum_links['delta_PC']\n",
    "visum_links['dtv_LCV'] = visum_links['dtv_SUM'] * visum_links['delta_LCV']\n",
    "visum_links['dtv_HGV'] = visum_links['dtv_SUM'] * visum_links['delta_HGV']\n",
    "\n",
    "visum_sum = visum_links.groupby('road_link_id').agg({'dtv_SUM': 'sum',\n",
    "                                                     'dtv_PC': 'sum',\n",
    "                                                     'dtv_HGV': 'sum',\n",
    "                                                     'dtv_LCV': 'sum',\n",
    "                                                     'road_type': lambda group: group.iloc[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_mean(input, iqr_range =(10, 99)):\n",
    "    lower_bound = np.percentile(input, iqr_range[0])\n",
    "    upper_bound = np.percentile(input, iqr_range[1])\n",
    "    return np.mean(input[(input >= lower_bound) & (input <= upper_bound)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_quantile_range(input, iqr_range =(10, 99)):\n",
    "    lower_bound = np.percentile(input, iqr_range[0])\n",
    "    upper_bound = np.percentile(input, iqr_range[1])\n",
    "    return input[(input >= lower_bound) & (input <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sqv(Observed, Model, f=10000):\n",
    "    # f = 10000 is the recommended factor for daily volumes \n",
    "    return 1/(1 + sqrt(pow( Model - Observed, 2) / (f * Observed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(mean, std, color=\"black\"):\n",
    "    x = np.linspace(mean-4*std, mean+4*std, 200)\n",
    "    p = stats.norm.pdf(x, mean, std)\n",
    "    z = plt.plot(x, p, color, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_normweekday_2019 = cnt_data_normweekday_2019.groupby(['road_link_id', 'vehicle_class'])['daily_value'].apply(iqr_mean)\n",
    "mean_normweekday_2019 = mean_normweekday_2019.reset_index().pivot(index='road_link_id', columns = 'vehicle_class')\n",
    "# combine visum and counting data\n",
    "combined = pd.concat([visum_sum, mean_normweekday_2019], axis =1).dropna()\n",
    "\n",
    "for vc in  ['SUM', 'PC', 'HGV', 'LCV']: \n",
    "    combined[f'{vc}_diff'] = combined[('daily_value', vc)] - combined[f'dtv_{vc}']\n",
    "    combined[f'{vc}_diff_r'] = (combined[f'{vc}_diff']/combined[('daily_value', vc)])*100\n",
    "\n",
    "combined['sqv_SUM'] = combined.apply(lambda row: calc_sqv(Observed=row[('daily_value', 'SUM')],\n",
    "                                                          Model = row['dtv_SUM']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(4,2, figsize = (10,12), squeeze=False, sharey=True)\n",
    "\n",
    "data = combined\n",
    "i = 0\n",
    "for vc in ['SUM', 'PC', 'LCV', 'HGV']:\n",
    "    \n",
    "    data_col1 = data[f'{vc}_diff']\n",
    "    data_col2 = data[f'{vc}_diff_r']\n",
    "    \n",
    "    sns.histplot(ax = ax[i, 0], data=data_col2)\n",
    "    sns.histplot(ax = ax[i, 1], data=data_col1)\n",
    "    ax[i, 0].set_title(f'{vc} - Relative Difference')\n",
    "    ax[i, 1].set_title(f'{vc} - Absolute Difference')\n",
    "    ax[i, 1].set_xlabel('#N')\n",
    "    ax[i, 0].set_xlabel('%')\n",
    "    \n",
    "    text = f'Mean: {data_col2.mean():.1f} %\\nMedian: {data_col2.median():.1f}%\\nStd: {data_col2.std():.1f}'\n",
    "    ax[i,0].text(.01, .99, text, ha='left', va='top', transform=ax[i,0].transAxes)\n",
    "    \n",
    "    text = f'Mean: {data_col1.mean():.1f}\\nMedian: {data_col1.median():.1f}\\nStd: {data_col1.std():.1f}'\n",
    "    ax[i,1].text(.01, .99, text, ha='left', va='top', transform=ax[i,1].transAxes)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "fig.suptitle('Difference Between VISUM Model And Counting Data')\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(2,2, figsize = (10,8))\n",
    "\n",
    "data = combined\n",
    "col = 0 \n",
    "row = 0\n",
    "\n",
    "for vc in ['SUM', 'PC', 'LCV', 'HGV']:\n",
    "    \n",
    "    data_x = data[('daily_value', vc)]\n",
    "    data_y = data[f'dtv_{vc}']\n",
    "    \n",
    "    sns.scatterplot(ax = ax[row, col], x=data_x, y=data_y, hue=combined['Road Type'])\n",
    "    ax[row, col].axline([0,0],[1,1])\n",
    "    ax[row, col].get_legend().remove()\n",
    "    \n",
    "    ax[row, col].set_ylabel('VISUM Model Count', fontsize = 12)\n",
    "    ax[row, col].set_xlabel('Traffic Count', fontsize = 12)\n",
    "    ax[row, col].set_title(f'{vc}', fontsize = 14)\n",
    "    \n",
    "    ax[row,col].set_xlim(0,max(pd.concat([data_x, data_y]))*1.1)\n",
    "    ax[row,col].set_ylim(0,max(pd.concat([data_x, data_y]))*1.1)\n",
    "    \n",
    "    r2 = r2_score(data_y, data_x)\n",
    "    \n",
    "    text = f'R2:{r2:.2f}'\n",
    "    ax[row,col].text(.05, .95, text, ha='left', va='top',\n",
    "                     transform=ax[row,col].transAxes, fontsize=12)\n",
    "    \n",
    "    col+=1\n",
    "    if col >= 2:\n",
    "        col=0\n",
    "        row +=1\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.15, 0.55), fontsize = 10)\n",
    "#fig.suptitle('VISUM Fit Statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,3))\n",
    "\n",
    "plt.axvspan(0.6, 1, color = 'orange', zorder = 0, alpha = 0.2)\n",
    "plt.axvspan(0.8, 1, color = 'green', zorder = 0, alpha = 0.4)\n",
    "plt.axvline(0.8, c = 'black')\n",
    "plt.axvline(0.6, c = 'black')\n",
    "plt.ylim(0,16)\n",
    "\n",
    "combined.rename(columns = {'road_type': 'Road Type'}, inplace = True)\n",
    "\n",
    "sns.histplot(data=combined, x = 'sqv_SUM', bins = 14, \n",
    "             binrange=(0.3,1), hue='Road Type', multiple='stack', \n",
    "             alpha = 0.8, legend=True)\n",
    "\n",
    "plt.text(0.61, 14, f'>0.6: {((len(combined[combined[\"sqv_SUM\"]>=0.6])/len(combined))*100):.1f}%', fontsize = 12)\n",
    "plt.text(0.81, 14, f'>0.8: {((len(combined[combined[\"sqv_SUM\"]>0.8])/len(combined))*100):.1f}%', fontsize = 12)\n",
    "\n",
    "plt.title('Scalable Quality Value (SQV)')\n",
    "plt.xlabel('SQV')\n",
    "plt.ylabel('Couning Stations [#N]')\n",
    "plt.show(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
