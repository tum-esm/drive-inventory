{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../utils')\n",
    "import data_paths\n",
    "from traffic_counts import TrafficCounts\n",
    "from hbefa_hot_emissions import HbefaHotEmissions\n",
    "from excel_calendar import Calendar\n",
    "\n",
    "import datetime\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import inventory_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import visum model\n",
    "visum = gpd.read_file(data_paths.VISUM_FOLDER_PATH + 'visum_links.gpkg')\n",
    "visum_red = visum.drop(visum.loc[(visum['road_type'] == 'none') | (visum['dtv_SUM']==0)].index, axis = 0)\n",
    "\n",
    "visum_red.loc[visum_red['road_type']=='Access-residential', 'road_type'] = 'Local/Collector'\n",
    "visum_red.loc[visum_red['road_type']=='Distributor/Secondary', 'road_type'] = 'TrunkRoad/Primary-National'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut visum model to the Munich area\n",
    "munich_boarders = gpd.read_file(data_paths.MUNICH_BOARDERS_FILE).to_crs(25832)\n",
    "visum_red = gpd.clip(visum_red, munich_boarders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded emission factors from /Users/daniel_tum/Documents/projects/traffic inventory v2/traffic-emission-inventory/data/restricted_input/hbefa/EFA_HOT_Vehcat_PC.XLS\n",
      "Loaded emission factors from /Users/daniel_tum/Documents/projects/traffic inventory v2/traffic-emission-inventory/data/restricted_input/hbefa/EFA_HOT_Vehcat_LCV.XLS\n",
      "Loaded emission factors from /Users/daniel_tum/Documents/projects/traffic inventory v2/traffic-emission-inventory/data/restricted_input/hbefa/EFA_HOT_Vehcat_HGV.XLS\n",
      "Loaded emission factors from /Users/daniel_tum/Documents/projects/traffic inventory v2/traffic-emission-inventory/data/restricted_input/hbefa/EFA_HOT_Vehcat_Coach.XLS\n",
      "Loaded emission factors from /Users/daniel_tum/Documents/projects/traffic inventory v2/traffic-emission-inventory/data/restricted_input/hbefa/EFA_HOT_Vehcat_MOT.XLS\n"
     ]
    }
   ],
   "source": [
    "# initialize calendar\n",
    "cal = Calendar()\n",
    "# initialize traffic cycles\n",
    "cycles = TrafficCounts()\n",
    "# initialize HBEFA emission factors\n",
    "hbefa = HbefaHotEmissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates for normweekdays in 2019\n",
    "dates = cal.get_calendar()\n",
    "normweekdays_2019 = dates[(dates['day_type'] == 1) &\n",
    "                          (dates['date'].between('2019-01-01','2019-12-31'))]\n",
    "\n",
    "# calculate vehicle shares on average norm weekday in 2019\n",
    "# these values are used to calculate the vehicle share correction factors\n",
    "weekday_shares_2019 = cycles.vehicle_shares.loc[:,normweekdays_2019['date']].reset_index()\n",
    "weekday_shares_2019 = weekday_shares_2019.groupby(['road_type','vehicle_class'])[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "visum_red['hgv_corr'] = visum_red.apply(lambda row : row['delta_HGV'] / weekday_shares_2019.loc[row['road_type'],'HGV'], axis = 1)\n",
    "visum_red['lcv_corr'] = visum_red.apply(lambda row : row['delta_LCV'] / weekday_shares_2019.loc[row['road_type'],'LCV'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_co2_emissions(date):\n",
    "    diurnal_cycles = cycles.get_hourly_scaling_factors(date=date)\n",
    "    vehicle_shares = cycles.get_vehicle_share(date=date).to_dict()\n",
    "    daily_scaling = cycles.get_daily_scaling_factors(date=date).to_dict()\n",
    "\n",
    "    em_sum_dict = dict()\n",
    "\n",
    "    for row in visum_red.to_dict('records'):\n",
    "\n",
    "        # get relevant information from the visum model\n",
    "        road_link_id = row['road_link_id']\n",
    "        dtv_visum = row['dtv_SUM']\n",
    "        road_type = row['road_type']\n",
    "        hour_capacity = row['hour_capacity']\n",
    "        visum_speed = row['speed']\n",
    "        visum_slope = row['SLOPE']\n",
    "        hgv_corr = row['hgv_corr']\n",
    "        lcv_corr = row['lcv_corr']\n",
    "        \n",
    "        # get vehicle shares from counting data\n",
    "        hgv_share = vehicle_shares['HGV'][road_type]\n",
    "        lcv_share = vehicle_shares['LCV'][road_type]\n",
    "        pc_share = vehicle_shares['PC'][road_type]\n",
    "        mot_share = vehicle_shares['MOT'][road_type]\n",
    "        bus_share = vehicle_shares['BUS'][road_type]\n",
    "        \n",
    "        # calculate vehicle share correction factor\n",
    "        k = (1- (hgv_corr * hgv_share)- (lcv_corr * lcv_share)) / (1 - hgv_share - lcv_share)\n",
    "        \n",
    "        # calculate vehicle counts and apply correction factor\n",
    "        dtv = dict()\n",
    "        dtv_day = dtv_visum * daily_scaling[road_type]\n",
    "        dtv.update({'HGV' : (dtv_day * hgv_share * hgv_corr)})\n",
    "        dtv.update({'LCV' : (dtv_day * lcv_share * lcv_corr)})\n",
    "        dtv.update({'PC' : (dtv_day * pc_share * k)})\n",
    "        dtv.update({'MOT' : (dtv_day * mot_share * k)})\n",
    "        dtv.update({'BUS' : (dtv_day * bus_share * k)})\n",
    "        \n",
    "        # calculate emissions on the respective road link    \n",
    "        em = hbefa.calculate_emissions_daily(dtv, diurnal_cycles, road_type,\n",
    "                                            visum_speed, visum_slope, hour_capacity, 2019)\n",
    "        \n",
    "        em_sum_dict.update({road_link_id:em})\n",
    "    print('Finished '+ date)\n",
    "    return em_sum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 2019-06-02\n"
     ]
    }
   ],
   "source": [
    "emissions = calculate_daily_co2_emissions(date = '2019-06-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PC': 30062.04579329592,\n",
       " 'LCV': 2222.5526366867243,\n",
       " 'HGV': 136.2454759394847,\n",
       " 'BUS': 1331.3181897838904,\n",
       " 'MOT': 787.8668404464042}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions[33564]['CO2(rep)']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
