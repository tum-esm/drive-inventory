{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Technical University of Munich<br>\n",
    "Professorship of Environmental Sensing and Modeling<br><br>*\n",
    "**Author:**  Ali Ahmad Khan<br>\n",
    "**Date:**  13.11.2023\n",
    "\n",
    "--- \n",
    "\n",
    "# LHM Counting Data processing\n",
    "\n",
    "This script loads the 'Jahresexport_MST_Detektoren*.csv', 'Q*_2019.csv' files, cleans the dataset and converts the data into a predetermined data model. Only the sensors present in 'mst_locations_selected.gpkg' are worked upon<br>\n",
    "\n",
    "**Required steps**\n",
    "- Import file and convert columns to meaningful datatypes\n",
    "- Delete meaningsless columns and rows for detectors not included in locations\n",
    "- Convert the ART column into given vehicle classes\n",
    "- Merge counting data with location data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# import custom modules\n",
    "sys.path.append('../../utils/')\n",
    "import data_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Clean raw data from *.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to mst counting data\n",
    "data_path = data_paths.MST_COUNTING_PATH\n",
    "\n",
    "# read the MST Locatins geo packaged file\n",
    "mst_loc = gpd.read_file(data_path+'mst_locations_selected.gpkg')\n",
    "\n",
    "# list of file patterns to match\n",
    "file_patterns = ['Jahresexport_MST_Detektoren*.csv', 'Q*_2019.csv']\n",
    "\n",
    "# Initializes an empty DataFrame\n",
    "mst_raw_combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterates over each file pattern\n",
    "for file_pattern in file_patterns:\n",
    "\n",
    "    # gets a list of file paths that match the pattern\n",
    "    file_paths = glob.glob(data_path + file_pattern)\n",
    "\n",
    "    # Iterates over the file paths and read each CSV file\n",
    "    for file_path in file_paths:\n",
    "\n",
    "        df = pd.read_csv(file_path, delimiter=';', decimal=',', encoding='ISO-8859-1')\n",
    "\n",
    "        # rename the columns of the all dfs retrived to match the first df retrieved\n",
    "        if not mst_raw_combined_df.empty:\n",
    "            \n",
    "            df.rename(index=str, columns=dict(zip(df.columns.to_list(), mst_raw_combined_df.columns.to_list())), inplace=True)\n",
    "\n",
    "        # concat the dataframes to contain data of all available years\n",
    "        mst_raw_combined_df = pd.concat([mst_raw_combined_df, df])\n",
    "\n",
    "# Keep rows only with MST_IDs that are present in out geopackage\n",
    "mst_raw_combined_df = mst_raw_combined_df[mst_raw_combined_df['MST'].isin(mst_loc['MST_ID'])]\n",
    "\n",
    "# Convert the Datetime format to YYYY-MM-DD\n",
    "mst_raw_combined_df['date'] = pd.to_datetime(mst_raw_combined_df['DATUM'],format='%d.%m.%Y')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "mst_raw_combined_df = mst_raw_combined_df.drop(['DATUM','MST','MQ','Unnamed: 30'], axis = 1)\n",
    "\n",
    "# Rename the columns to their english alternatives\n",
    "mst_raw_combined_df.rename(columns={'DETEKTOR_ID': 'detector_id', 'TAGES_SUMME':'daily_value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "\n",
    "### Create Datframe for volume of traffic for lhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to convert ART volume values to vehicle class\n",
    "art_to_vehicle_class = {   \n",
    "                    'QPKW': 'PKW',\n",
    "                    'QLFW': 'LNF',\n",
    "                    'QPKWA': 'LNF',\n",
    "                    'QNK_KFZ': 'SNF',\n",
    "                    'QLKWA': 'SNF',\n",
    "                    'QLKW': 'SNF',\n",
    "                    'QSATTEL_KFZ': 'SNF',\n",
    "                    'QBUS': 'BUS',\n",
    "                    'QKRAD': 'MOT'\n",
    "                }\n",
    "\n",
    "# create raw volume dataframe \n",
    "mst_raw_volume = mst_raw_combined_df.copy()\n",
    "\n",
    "# map the art volume categories to vehicles class\n",
    "mst_raw_volume['vehicle_class'] = mst_raw_volume['ART'].map(art_to_vehicle_class)\n",
    "\n",
    "# drop the art column\n",
    "mst_raw_volume = mst_raw_volume.drop(['ART'], axis = 1)\n",
    "\n",
    "# group by all vehicles classes\n",
    "mst_raw_volume = mst_raw_volume.groupby(['date', 'detector_id', 'vehicle_class'], as_index=False).sum()\n",
    "\n",
    "# assign the detectors their type\n",
    "mst_raw_volume['detector_type'] = np.where(mst_raw_volume['vehicle_class'].isna(), np.NaN, '8+1')\n",
    "\n",
    "# create a metric column with volume value \n",
    "mst_raw_volume['metric'] = 'volume'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datframe for speed of traffic for lhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to convert ART speed values to vehicle class \n",
    "art_to_vehicle_class = {   \n",
    "                    'VPKW': 'PKW',\n",
    "                    'VLFW': 'LNF',\n",
    "                    'VPKWA': 'LNF',\n",
    "                    'VNK_KFZ': 'SNF',\n",
    "                    'VLKWA': 'SNF',\n",
    "                    'VLKW': 'SNF',\n",
    "                    'VSATTEL_KFZ': 'SNF',\n",
    "                    'VBUS': 'BUS',\n",
    "                    'VKRAD': 'MOT'\n",
    "                }\n",
    "\n",
    "# create raw speed dataframe \n",
    "mst_raw_speed = mst_raw_combined_df.copy()\n",
    "\n",
    "# map the art speed categories to vehicles class\n",
    "mst_raw_speed['vehicle_class'] = mst_raw_speed['ART'].map(art_to_vehicle_class)\n",
    "\n",
    "# map the art speed categories to vehicles class\n",
    "mst_raw_speed = mst_raw_speed.drop(['ART'], axis = 1)\n",
    "\n",
    "# group by all vehicles classes\n",
    "mst_raw_speed = mst_raw_speed.groupby(['date', 'detector_id', 'vehicle_class'], as_index=False).mean()\n",
    "\n",
    "# assign the detectors their type\n",
    "mst_raw_speed['detector_type'] = np.where(mst_raw_speed['vehicle_class'].isna(), np.NaN, '8+1')\n",
    "\n",
    "# create a metric column with speed value \n",
    "mst_raw_speed['metric'] = 'speed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the volume and speed dataframes for lhm & Merge with location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the volume and speed dataframes together\n",
    "mst_concat = pd.concat([mst_raw_speed, mst_raw_volume])\n",
    "\n",
    "# Join the mst_concate dataframe with the locations data\n",
    "mst_preprocessed = mst_concat.merge(mst_loc, how = 'left', left_on = 'detector_id', right_on = 'DETEKTOR_ID')\n",
    "\n",
    "# Ordered the columns into predetermined order\n",
    "mst_preprocessed = mst_preprocessed[['date','road_link_id','detector_id','detector_type','vehicle_class','metric','daily_value',\n",
    "       \"00:00-01:00\", '01:00-02:00', '02:00-03:00', '03:00-04:00',\n",
    "       '04:00-05:00', '05:00-06:00', '06:00-07:00', '07:00-08:00',\n",
    "       '08:00-09:00', '09:00-10:00', '10:00-11:00', '11:00-12:00',\n",
    "       '12:00-13:00', '13:00-14:00', '14:00-15:00', '15:00-16:00',\n",
    "       '16:00-17:00', '17:00-18:00', '18:00-19:00', '19:00-20:00',\n",
    "       '20:00-21:00', '21:00-22:00', '22:00-23:00', '23:00-24:00']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store as parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataframe as a parquet file\n",
    "mst_preprocessed.to_parquet(data_path+'preprocessed_lhm_counting_data.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
