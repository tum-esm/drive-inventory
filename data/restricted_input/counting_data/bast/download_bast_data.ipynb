{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process BAST traffic count data\n",
    "Source: https://www.bast.de/BASt_2017/DE/Verkehrstechnik/Fachthemen/v2-verkehrszaehlung/zaehl_node.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for download \n",
    "Functions for download and unzip BAST hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual downloading -> Author: Johannes Gensheimer\n",
    "def DownloadURL(url, save_path):\n",
    "    #function from: https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url/14260592\n",
    "    \n",
    "    chunk_size=128\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "#call download and unzip\n",
    "def DownloadHourData_BAST(CounterNumber, year, FolderSave):\n",
    "\n",
    "    BAST_Link = 'https://www.bast.de/videos/' + str(year) + '/zst' + str(CounterNumber) + '.zip'\n",
    "    FileName = FolderSave + 'zst' + str(CounterNumber) + '_' + str(year) + '.zip'\n",
    "\n",
    "    #download zip\n",
    "    DownloadURL(BAST_Link, FileName)\n",
    "    \n",
    "    #unzip file if downloading was successfull\n",
    "    zf = ZipFile(FileName, 'r')\n",
    "    zf.extractall(FolderSave)\n",
    "    zf.close()\n",
    "\n",
    "    #remove zip file\n",
    "    os.system('rm ' + FileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process download request \n",
    "DZ_Nr_unique: Number of counting stations <br>\n",
    "years: years that should be downloaded <br>\n",
    "path: path to temp directory where the downloaded data is temporary stored <br>\n",
    "keepOrigData: Bool if downloaded raw data should be deleted: True: not deleted, False: deleted <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(DZ_Nr_unique, years, path, keepOrigData):\n",
    "\n",
    "    #sort years array ascending\n",
    "    years.sort()\n",
    "    print(years)\n",
    "    \n",
    "    #create temporary directory\n",
    "    if not os.path.exists(path):\n",
    "        os.system('mkdir ' + path)\n",
    "\n",
    "    #total number of counting stations that should be processed\n",
    "    total_count = len(DZ_Nr_unique)\n",
    "\n",
    "    #some prints\n",
    "    print('All counter stations: ', DZ_Nr_unique)\n",
    "    print('In total # = ', total_count)\n",
    "    count = 1\n",
    "    \n",
    "    # empty dataframe for all data\n",
    "    df_all = pd.DataFrame()\n",
    "    \n",
    "    #loop over all counting stations\n",
    "    for nr in range(0,len(DZ_Nr_unique)):\n",
    "        \n",
    "        DZ_Nr = DZ_Nr_unique[nr]\n",
    "        print('Processing ' , count, ' of ', total_count)\n",
    "        count = count + 1\n",
    "        \n",
    "        #loop over years\n",
    "        for year in years:\n",
    "            \n",
    "            #filename in temp dir\n",
    "            f = 'zst' + str(DZ_Nr) + '_' + str(year) + '.csv'\n",
    "            try:\n",
    "                #download data\n",
    "                DownloadHourData_BAST(DZ_Nr, year, path)\n",
    "                \n",
    "                df = pd.read_csv(path+f, delimiter=';')\n",
    "                df_all = pd.concat([df_all, df], axis = 0)\n",
    "                    \n",
    "                #remove downloaded file if keepOrigData not True\n",
    "                if not keepOrigData:\n",
    "                    os.system('rm ' + path + f)\n",
    "            except Exception as e:\n",
    "                print(\"Could not download data for:\"+str(DZ_Nr_unique[nr])+\"/\"+str(year))\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unused_locations(location_list, path):\n",
    "    locations = ['BY' + str(location) for location in location_list]\n",
    "    # print(f\"Deleting data of unused locations\")\n",
    "    for folder in os.listdir(path):\n",
    "        if folder == '.DS_Store': continue\n",
    "        new_path = os.path.join(path, folder)\n",
    "        for file in os.listdir(new_path):\n",
    "            temp_path = os.path.join(new_path, file)\n",
    "            if os.path.isfile(temp_path) and not (str(file[:6]) in locations):\n",
    "                    os.system('rm ' + temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_append_raw_data(df_old, path, newFile='BAST_CountingStations_daily_new.csv'):\n",
    "     \n",
    "    for folder in os.listdir(path):\n",
    "        if folder == '.DS_Store': continue\n",
    "        print(f\"Processing {folder}\")\n",
    "        new_path = os.path.join(path, folder + '/')\n",
    "        for file in os.listdir(new_path):\n",
    "\n",
    "            # Handle header rows individually, due to different number of elements\n",
    "            df_header1 = pd.read_csv(new_path + file, encoding= 'unicode_escape', nrows=1, header=None, delim_whitespace=True)\n",
    "            df_header2 = pd.read_csv(new_path + file, encoding= 'unicode_escape', nrows=1, header=None, delim_whitespace=True, skiprows=1)\n",
    "            df_header3 = pd.read_csv(new_path + file, encoding= 'unicode_escape', nrows=1, header=None, delim_whitespace=True, skiprows=2)\n",
    "\n",
    "            # Copy Dataframe Schema\n",
    "            df_new = pd.DataFrame().reindex_like(df_old).dropna()\n",
    "            df_body = pd.read_csv(new_path + file, encoding= 'unicode_escape', skiprows=3, header=None,  delim_whitespace=True)   \n",
    "            \n",
    "            # Drop faulty line (necessary because of measurements in march for some reason)\n",
    "            df_body = df_body.drop(df_body[df_body[0].astype(str).str.contains('i', regex=False)].index)\n",
    "\n",
    "        # Extract data from header\n",
    "            df_new['Datum'] = df_body[0]\n",
    "            df_new['Stunde'] = df_body[1].str.split(\":\").str[0].astype(int)\n",
    "            df_new['KFZ_R1'] = df_body[2]\n",
    "            df_new['Wotag'] = pd.to_datetime(df_new['Datum'].astype(str), format='%y%m%d').dt.weekday\n",
    "            df_new['Wotag'] += 1 # dt.weekday specifies Monday=0 .. Sunday=6\n",
    "\n",
    "            # Fill NaN's with 0\n",
    "            df_new = df_new.fillna(0)\n",
    "\n",
    "            # Extract necessary information\n",
    "            df_new = df_new.assign(TKNR=df_header1.iloc[0, 0][1:5])\n",
    "            df_new = df_new.assign(Zst = df_header1.iloc[0, 0][5:9])\n",
    "            df_new = df_new.assign(Land = df_header1.iloc[0, 1])\n",
    "            df_new = df_new.assign(Strklas = df_header1.iloc[0, 2])\n",
    "            df_new = df_new.assign(Strnum = df_header1.iloc[0, 3])\n",
    "            df_new = df_new.assign(Fahrtzw = 'n')\n",
    "\n",
    "            # number of lanes in each direction\n",
    "            lanes_per_direction = [int(df_header2.iloc[0, 0][1:]), int(df_header2.iloc[0, 1])]\n",
    "            offset_date_time = 2\n",
    "            offset_kfz_sv = 2 * (lanes_per_direction[0] + lanes_per_direction[1])\n",
    "\n",
    "            # For some reason 1 station is different than all the other stations..\n",
    "            if 'BY9223' in file:\n",
    "                column = 'KFZ_R'\n",
    "\n",
    "                for direction in range(2): # code only works for 2 directions\n",
    "                    # KFZ and LKW (SV)\n",
    "                    count_name = column + str(direction + 1)\n",
    "                    check_name = 'K_' + column + str(direction + 1)\n",
    "                    df_temp_count = df_body.iloc[:][offset_date_time + (direction * lanes_per_direction[0])].str.strip().str[:-1].astype(int)\n",
    "                    df_temp_check = df_body.iloc[:][offset_date_time + (direction * lanes_per_direction[0])].str.strip().str[-1:]\n",
    "                    for lane in range(1, lanes_per_direction[direction]):\n",
    "                        df_temp_count += df_body.iloc[:][offset_date_time + (direction * lanes_per_direction[0]) + lane].str.strip().str[:-1].astype(int)\n",
    "\n",
    "                    df_new[count_name] = df_temp_count\n",
    "                    df_new[check_name] = df_temp_check\n",
    "            else: \n",
    "\n",
    "                columns_kfz_lkw = ['KFZ_R', 'Lkw_R']\n",
    "                columns_rest = ['Mot_R', 'Pkw_R', 'Lfw_R', 'PmA_R', 'Bus_R',\n",
    "                                'LoA_R', 'Lzg_R', 'Sat_R', 'Son_R'] # attention, Lzg = LmA + Sat\n",
    "                columns_calc = ['PLZ_R', 'Lzg_R'] # Lzg = LmA + Sat, PLZ = Mot + Pkw + Lfw\n",
    "\n",
    "                for direction in range(2):\n",
    "                    # KFZ and LKW (SV)\n",
    "                    for idx, column in enumerate(columns_kfz_lkw):\n",
    "                        count_name = column + str(direction + 1)\n",
    "                        check_name = 'K_' + column + str(direction + 1)\n",
    "                        df_temp_count = df_body.iloc[:][offset_date_time + idx + (direction * 2 * lanes_per_direction[0])].str.strip().str[:-1].astype(int)\n",
    "                        df_temp_check = df_body.iloc[:][offset_date_time + idx + (direction * 2 * lanes_per_direction[0])].str.strip().str[-1:]\n",
    "                        for lane in range(1, lanes_per_direction[direction]):\n",
    "                            df_temp_count += df_body.iloc[:][offset_date_time + idx + (direction * 2 * lanes_per_direction[0]) + (2 * lane)].str.strip().str[:-1].astype(int)\n",
    "\n",
    "                        df_new[count_name] = df_temp_count\n",
    "                        df_new[check_name] = df_temp_check\n",
    "                    # Other classes\n",
    "                    for idx, column in enumerate(columns_rest):\n",
    "                        count_name = column + str(direction + 1)\n",
    "                        check_name = 'K_' + column + str(direction + 1)\n",
    "                        df_temp_count = df_body.iloc[:][offset_date_time + offset_kfz_sv + idx + (direction * 9 * lanes_per_direction[0])].str.strip().str[:-1].astype(int)\n",
    "                        df_temp_check = df_body.iloc[:][offset_date_time + offset_kfz_sv + idx + (direction * 9 * lanes_per_direction[0])].str.strip().str[-1:]\n",
    "                        for lane in range(1, lanes_per_direction[direction]):\n",
    "                            df_temp_count += df_body.iloc[:][offset_date_time + offset_kfz_sv + idx + (direction * 9 * lanes_per_direction[0]) + (9 * lane)].str.strip().str[:-1].astype(int)\n",
    "                        df_new[count_name] = df_temp_count\n",
    "                        df_new[check_name] = df_temp_check\n",
    "\n",
    "                    # Lzg = LmA + Sat\n",
    "                    df_new['Lzg_R' + str(direction + 1)] += df_new['Sat_R' + str(direction + 1)]\n",
    "                    # PLZ = Mot + Pkw + Lfw\n",
    "                    df_new['PLZ_R' + str(direction + 1)] = df_new['Mot_R' + str(direction + 1)] + df_new['Pkw_R' + str(direction + 1)] + df_new['Lfw_R' + str(direction + 1)]\n",
    "                    df_new['K_PLZ_R' + str(direction + 1)] = df_new['K_Mot_R' + str(direction + 1)] # Not sure how to handle this  \n",
    "            df_old = pd.concat([df_old, df_new])\n",
    "        print(f\"Completed {folder}\")\n",
    "    print(f\"Writing to file {newFile}\")\n",
    "    df_old.to_csv(newFile)\n",
    "    return df_old\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018 2019 2020 2021]\n",
      "All counter stations:  [9140 9141 9772 9773 9082 9003 9083 9115 9066 9063 9242 9064 9217 9006\n",
      " 9987 9986 9985 9151 9043 9222 9106 9207 9775 9774 9215 9212 9213 9220\n",
      " 9219 9218 9211 9155 9228 9244 9229 9221 9830 9820 9810 9320 9102 9988]\n",
      "In total # =  42\n",
      "Processing  1  of  42\n",
      "Processing  2  of  42\n",
      "Processing  3  of  42\n",
      "Could not download data for:9772/2021\n",
      "Processing  4  of  42\n",
      "Could not download data for:9773/2018\n",
      "Could not download data for:9773/2019\n",
      "Could not download data for:9773/2020\n",
      "Could not download data for:9773/2021\n",
      "Processing  5  of  42\n",
      "Could not download data for:9082/2018\n",
      "Could not download data for:9082/2019\n",
      "Could not download data for:9082/2020\n",
      "Processing  6  of  42\n",
      "Processing  7  of  42\n",
      "Could not download data for:9083/2018\n",
      "Could not download data for:9083/2019\n",
      "Could not download data for:9083/2020\n",
      "Processing  8  of  42\n",
      "Could not download data for:9115/2018\n",
      "Could not download data for:9115/2019\n",
      "Processing  9  of  42\n",
      "Processing  10  of  42\n",
      "Could not download data for:9063/2019\n",
      "Processing  11  of  42\n",
      "Processing  12  of  42\n",
      "Processing  13  of  42\n",
      "Processing  14  of  42\n",
      "Processing  15  of  42\n",
      "Could not download data for:9987/2020\n",
      "Processing  16  of  42\n",
      "Could not download data for:9986/2018\n",
      "Could not download data for:9986/2019\n",
      "Could not download data for:9986/2020\n",
      "Could not download data for:9986/2021\n",
      "Processing  17  of  42\n",
      "Could not download data for:9985/2020\n",
      "Could not download data for:9985/2021\n",
      "Processing  18  of  42\n",
      "Could not download data for:9151/2018\n",
      "Could not download data for:9151/2019\n",
      "Could not download data for:9151/2020\n",
      "Could not download data for:9151/2021\n",
      "Processing  19  of  42\n",
      "Could not download data for:9043/2018\n",
      "Processing  20  of  42\n",
      "Could not download data for:9222/2019\n",
      "Could not download data for:9222/2020\n",
      "Processing  21  of  42\n",
      "Processing  22  of  42\n",
      "Processing  23  of  42\n",
      "Could not download data for:9775/2020\n",
      "Processing  24  of  42\n",
      "Processing  25  of  42\n",
      "Could not download data for:9215/2021\n",
      "Processing  26  of  42\n",
      "Could not download data for:9212/2020\n",
      "Could not download data for:9212/2021\n",
      "Processing  27  of  42\n",
      "Could not download data for:9213/2019\n",
      "Processing  28  of  42\n",
      "Could not download data for:9220/2020\n",
      "Processing  29  of  42\n",
      "Processing  30  of  42\n",
      "Could not download data for:9218/2018\n",
      "Could not download data for:9218/2019\n",
      "Could not download data for:9218/2020\n",
      "Could not download data for:9218/2021\n",
      "Processing  31  of  42\n",
      "Could not download data for:9211/2018\n",
      "Could not download data for:9211/2019\n",
      "Could not download data for:9211/2020\n",
      "Could not download data for:9211/2021\n",
      "Processing  32  of  42\n",
      "Could not download data for:9155/2021\n",
      "Processing  33  of  42\n",
      "Could not download data for:9228/2018\n",
      "Could not download data for:9228/2019\n",
      "Could not download data for:9228/2020\n",
      "Processing  34  of  42\n",
      "Processing  35  of  42\n",
      "Could not download data for:9229/2018\n",
      "Could not download data for:9229/2019\n",
      "Could not download data for:9229/2020\n",
      "Could not download data for:9229/2021\n",
      "Processing  36  of  42\n",
      "Could not download data for:9221/2021\n",
      "Processing  37  of  42\n",
      "Could not download data for:9830/2018\n",
      "Could not download data for:9830/2019\n",
      "Processing  38  of  42\n",
      "Could not download data for:9820/2018\n",
      "Processing  39  of  42\n",
      "Could not download data for:9810/2018\n",
      "Processing  40  of  42\n",
      "Could not download data for:9320/2018\n",
      "Could not download data for:9320/2019\n",
      "Could not download data for:9320/2020\n",
      "Processing  41  of  42\n",
      "Could not download data for:9102/2018\n",
      "Could not download data for:9102/2019\n",
      "Could not download data for:9102/2020\n",
      "Could not download data for:9102/2021\n",
      "Processing  42  of  42\n",
      "Could not download data for:9988/2018\n",
      "Could not download data for:9988/2019\n",
      "Could not download data for:9988/2020\n"
     ]
    }
   ],
   "source": [
    "bast_locations = gpd.read_file('bast_locations_selected.gpkg')\n",
    "station_ids = np.array(bast_locations['MST_ID'].unique()) # counting station number\n",
    "\n",
    "years = np.array([2018,2019,2020,2021]) # years of interst\n",
    "\n",
    "# download processed datasets from BAST homepage\n",
    "df_daily = Process(station_ids, years, path='temp/', keepOrigData=False)\n",
    "df_daily.to_csv('BAST_CountingStations_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DZ_2022_01_Rohdaten\n",
      "Completed DZ_2022_01_Rohdaten\n",
      "Processing DZ_2022_07_Rohdaten\n",
      "Completed DZ_2022_07_Rohdaten\n",
      "Processing DZ_2022_06_Rohdaten\n",
      "Completed DZ_2022_06_Rohdaten\n",
      "Processing DZ_2022_10_Rohdaten\n",
      "Completed DZ_2022_10_Rohdaten\n",
      "Processing DZ_2022_11_Rohdaten\n",
      "Completed DZ_2022_11_Rohdaten\n",
      "Processing DZ_2022_09_Rohdaten\n",
      "Completed DZ_2022_09_Rohdaten\n",
      "Processing DZ_2022_08_Rohdaten\n",
      "Completed DZ_2022_08_Rohdaten\n",
      "Processing DZ_2022_03_Rohdaten\n",
      "Completed DZ_2022_03_Rohdaten\n",
      "Processing DZ_2022_02_Rohdaten\n",
      "Completed DZ_2022_02_Rohdaten\n",
      "Processing DZ_2022_12_Rohdaten\n",
      "Completed DZ_2022_12_Rohdaten\n",
      "Processing DZ_2022_04_Rohdaten\n",
      "Completed DZ_2022_04_Rohdaten\n",
      "Processing DZ_2022_05_Rohdaten\n",
      "Completed DZ_2022_05_Rohdaten\n",
      "Writing to file BAST_CountingStations_daily_new.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TKNR</th>\n",
       "      <th>Zst</th>\n",
       "      <th>Land</th>\n",
       "      <th>Strklas</th>\n",
       "      <th>Strnum</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Wotag</th>\n",
       "      <th>Fahrtzw</th>\n",
       "      <th>Stunde</th>\n",
       "      <th>KFZ_R1</th>\n",
       "      <th>...</th>\n",
       "      <th>Bus_R2</th>\n",
       "      <th>K_Bus_R2</th>\n",
       "      <th>LoA_R2</th>\n",
       "      <th>K_LoA_R2</th>\n",
       "      <th>Lzg_R2</th>\n",
       "      <th>K_Lzg_R2</th>\n",
       "      <th>Sat_R2</th>\n",
       "      <th>K_Sat_R2</th>\n",
       "      <th>Son_R2</th>\n",
       "      <th>K_Son_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7834</td>\n",
       "      <td>9140</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>180101</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7834</td>\n",
       "      <td>9140</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>180101</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7834</td>\n",
       "      <td>9140</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>180101</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>3</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7834</td>\n",
       "      <td>9140</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>180101</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7834</td>\n",
       "      <td>9140</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>180101</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>7936</td>\n",
       "      <td>9244</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>220531</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>20</td>\n",
       "      <td>1967</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>184</td>\n",
       "      <td>-</td>\n",
       "      <td>154</td>\n",
       "      <td>-</td>\n",
       "      <td>25</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>7936</td>\n",
       "      <td>9244</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>220531</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>21</td>\n",
       "      <td>1302</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>121</td>\n",
       "      <td>-</td>\n",
       "      <td>103</td>\n",
       "      <td>-</td>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>7936</td>\n",
       "      <td>9244</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>220531</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>22</td>\n",
       "      <td>865</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>17</td>\n",
       "      <td>-</td>\n",
       "      <td>105</td>\n",
       "      <td>-</td>\n",
       "      <td>81</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>7936</td>\n",
       "      <td>9244</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>220531</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>23</td>\n",
       "      <td>733</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>112</td>\n",
       "      <td>-</td>\n",
       "      <td>94</td>\n",
       "      <td>-</td>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>7936</td>\n",
       "      <td>9244</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>220531</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>24</td>\n",
       "      <td>402</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>19</td>\n",
       "      <td>-</td>\n",
       "      <td>83</td>\n",
       "      <td>-</td>\n",
       "      <td>68</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270734 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TKNR   Zst  Land Strklas  Strnum   Datum  Wotag Fahrtzw  Stunde  KFZ_R1  \\\n",
       "0    7834  9140     9       A       8  180101      1       s       1      76   \n",
       "1    7834  9140     9       A       8  180101      1       s       2     222   \n",
       "2    7834  9140     9       A       8  180101      1       s       3     237   \n",
       "3    7834  9140     9       A       8  180101      1       s       4     149   \n",
       "4    7834  9140     9       A       8  180101      1       s       5      95   \n",
       "..    ...   ...   ...     ...     ...     ...    ...     ...     ...     ...   \n",
       "739  7936  9244     9       A      99  220531      2       n      20    1967   \n",
       "740  7936  9244     9       A      99  220531      2       n      21    1302   \n",
       "741  7936  9244     9       A      99  220531      2       n      22     865   \n",
       "742  7936  9244     9       A      99  220531      2       n      23     733   \n",
       "743  7936  9244     9       A      99  220531      2       n      24     402   \n",
       "\n",
       "     ... Bus_R2  K_Bus_R2 LoA_R2  K_LoA_R2 Lzg_R2  K_Lzg_R2 Sat_R2  K_Sat_R2  \\\n",
       "0    ...      0         a      0         a      0         a      0         a   \n",
       "1    ...      0         a      0         a      0         a      0         a   \n",
       "2    ...      0         a      0         a      0         a      0         a   \n",
       "3    ...      0         a      0         a      0         a      0         a   \n",
       "4    ...      0         a      0         a      0         a      0         a   \n",
       "..   ...    ...       ...    ...       ...    ...       ...    ...       ...   \n",
       "739  ...      8         -     40         -    184         -    154         -   \n",
       "740  ...     11         -     20         -    121         -    103         -   \n",
       "741  ...      2         -     17         -    105         -     81         -   \n",
       "742  ...      4         -     12         -    112         -     94         -   \n",
       "743  ...      4         -     19         -     83         -     68         -   \n",
       "\n",
       "    Son_R2  K_Son_R2  \n",
       "0        0         a  \n",
       "1        0         a  \n",
       "2        0         a  \n",
       "3        0         a  \n",
       "4        0         a  \n",
       "..     ...       ...  \n",
       "739     25         -  \n",
       "740     11         -  \n",
       "741     20         -  \n",
       "742     11         -  \n",
       "743      8         -  \n",
       "\n",
       "[1270734 rows x 57 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data\n",
    "\n",
    "# create temporary directory to save raw data for the raw data download  \n",
    "temp_path = 'temp_raw/'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.makedirs(temp_path)\n",
    "    \n",
    "# Download raw data from BAST was performed manually from the follwowing link and unzipped into the temp_raw/ folder\n",
    "# URL = 'https://www.bast.de/DE/Publikationen/Daten/Verkehrstechnik/DZ.html'\n",
    "# the downloaded zip file contains zip files for each month\n",
    "\n",
    "# Remove stations not in DZ_Nr_arr\n",
    "delete_unused_locations(station_ids, temp_path)\n",
    "# extract and append raw data to previous df\n",
    "extract_append_raw_data(df_daily, temp_path, 'BAST_CountingStations_daily_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('BAST_CountingStations_daily_new.csv', index_col=0).sort_values('Datum')\n",
    "df_test.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
